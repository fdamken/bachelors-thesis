\chapter{Introduction}
\label{c:introduction}
\IMRADlabel{introduction}



A dynamical system often describes some kind of physical process, \eg a pendulum swinging around a fixed point or two pendulums together. However, these systems often exhibit complicated and tedious movements, in some cases even chaotic movement. In (optimal) control theory, we try to (optimally) control these systems, \eg stand upright. As for complex systems we do not necessarily have the motions of equation (\eg with friction models), we have to learn the model in a process called \emph{model learning}.

\paragraph{Motivation}
	Unfortunately, learning nonlinear models is a tedious task. For (optimal) control, there are highly evolved control methods like \ac{lqr} to get an optimal trajectory. Unfortunately, such evolved solution theory does not exist for nonlinear models, even if we would have perfect models. Most methods used for control, \eg \ac{mpc} and \ac{ilqr}, use approximations and locally linear dynamics models.

	This motivates finding globally linear embeddings that we can lift the nonlinear dynamics to. This enables doing control in the linear embedding rather than the complex nonlinear state space, yielding better overall results.
% end

\paragraph{Approach}
	Motivated from the complex behavior of nonlinear systems, we seek a linear embedding that we can lift the nonlinear dynamics into. In this linear embedding, we might be able to do linear control instead of tedious nonlinear control. This approach is theoretically backed by Koopman theory~\cite{koopmanHamiltonianSystemsTransformation1931}, stating that every dynamical system can be lifted into a linear embedding. Such methods have proven to be useful in the past~\cite{kaiserDatadrivenDiscoveryKoopman2020,hanDeepLearningKoopman2020,mortonDeepVariationalKoopman2019a}, however most of the approaches do not tackle the problem from a probabilistic view or have very complex models.
% end

\paragraph{Contribution}
	Our contribution is an extension of the well-known model learning algorithm for \acp{lgds}~\cite{ghahramaniParameterEstimationLinear1996,minkaHiddenMarkovModels1999} by using nonlinear measurements. Backed from Koopman theory~\cite{koopmanHamiltonianSystemsTransformation1931} and results from prior work~\cite{luschDeepLearningUniversal2018}, we assume the existence of an observation function that maps from a linear Koopman embedding to the nonlinear state space, allowing model forecasting.

	We evaluate our model on well-known environments like the (damped) pendulum, cartpole and a double pendulum. Finally, we examine the model performance on an error-basis and explore the influence of hyperparameters to the performance.
% end

\paragraph{Goals}
	Our goal is to provide a compact and easy-to-train model for learning nonlinear dynamical systems in a linear embedding with decent forecasting abilities. This lays the groundwork for future modification in control and Bayesian treatment of the model.
% end

\paragraph{Outline}
	In \chapterautorefname~"\nameref{c:preliminaries}" we give an overview over the basic techniques we use throughout this thesis, namely dynamical systems, the Koopman operator and the expectation-maximization algorithm. Afterwards we give an introduction to inference in dynamical systems in~\autoref{c:inferenceInDynamicalSystems}, laying the groundwork for the following chapters that include our contribution. In \chapterautorefname~"\nameref{c:nonlinearGaussianKoopman}", we state the problem to solve formally and propose a method to solve the upcoming inference problem using an approximate nonlinear expectation-maximization algorithm utilizing cubature rules. We will also cover implementation details and assess the numerical stability of our algorithm. We will cover experiments and experimental results in~\autoref{c:experiments} and discuss the results in~\autoref{c:discussion}, giving also some ideas on future work. Finally, we summarize all results in~\autoref{c:conclusion}.
% end
