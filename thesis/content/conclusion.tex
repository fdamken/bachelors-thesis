\chapter{Conclusion}
\label{c:conclusion}



Linearization is very important in control to handle nonlinear systems that exhibit complicated dynamics. We have looked at Koopman theory, a technique to find globally linear embedding for a nonlinear system. Unfortunately, the Koopman operator, the core of Koopman theory, is generally infinite-dimensional. Prior work~\cite{bruntonKoopmanInvariantSubspaces2016,kaiserDatadrivenDiscoveryKoopman2020,luschDeepLearningUniversal2018} has shown that we can find a finite-dimensional representation of the operator. These representations seek Koopman eigenfunctions that span an invariant subspace of the embedding and do not transform under the influence of the Koopman operator other than being scaled. Nevertheless, most of the existing approaches work on deterministic models, seeking the Koopman eigenfunctions. While methods have been proposed to take a probabilistic perspective on the Koopman operator, these methods use complicated model setups with multiple neural networks and do not directly gauge the uncertainty of model predictions.

We have combined existing theory for \acl{lgds} with cubature rules to approximate arising nonlinear Gaussian integrals in a deterministic way to build up an \acl{em} algorithm. We called the result algorithm the \emph{Koopman inference} algorithm. It is alternating between estimating the states in the E-step and optimizing the linear latent state dynamics and a nonlinear observation function that maps the linear latent states back to the nonlinear dynamics. This way, we were able to predict the nonlinear dynamics and learned the Koopman observation functions without hand-tuned loss functions like in~\cite{luschDeepLearningUniversal2018}.

We evaluated the model performance on multiple different environments: A simple pendulum, a damped pendulum, the cartpole environment and a double pendulum. We used two different approaches for learning the dynamics of the pendulum, one of which uses sine/cosine feature transformations of the pendulum displacement and one that learn the angle directly. We also proved and showed empirically that our algorithm extends the common algorithm for learning \ac{lgds} by showing that the used  integral approximations are exact for linear functions and validating the result on a regular \ac{lgds}. We have found out that learning systems that lose energy (\eg the damped pendulum) are generally easier to learn as systems that conserve energy (\eg the undamped pendulum), as the the latent dynamics have to be stable but not attract zero to keep moving. Additionally, we discovered that the pendulum with sine/cosine features is a lot harder to learn, presumably because of the additional nonlinearity added by the feature transformation. Also, we roughly learned the dynamics of the double pendulum environment, even though this is a chaotic system and we were not able to predict further movements beyond the training data.

Finally, we compared our Koopman inference algorithm against the \acl{dvk} model proposed by~\cite{mortonDeepVariationalKoopman2019a}. We saw that our algorithm performs similar, however, the \ac{dvk} model is better in predicting the dynamics beyond the training data, while we are primarily able to predict until the end of the training data. We should note that the \ac{dvk} performs reconstruction from the latents that were learned during the training while our model performs the rollout from the beginning.

Overall we are satisfied with the performance of the Koopman inference algorithm and it allows for further improvements of learning the influence of control inputs on actuated systems or employing a Bayesian view on the latent dimensions and further gauge the uncertainty on the state dynamics.
